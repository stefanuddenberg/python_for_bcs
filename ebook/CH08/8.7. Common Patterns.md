# 8.7 Common Patterns

Now that we've covered the basics of the Python language, this section aggregates common code patterns you'll use and
encounter frequently. Think of these as ready-to-use templates that you can adapt for your specific needs. You don't
have to memorize them all or read through this section in one go — think of this more like a cheat sheet you can come back to as needed.

## Anonymous functions

Lambda functions or anonymous functions (see [Chapter 3.0. Functions](../CH03/3.0.%20Functions.md) for a refresher) provide a way
to create small, single-expression functions inline. They're particularly useful when you need a simple function as an
argument to another function. Below I'll outline some common patterns for using lambda functions.

### Sorting with lambda functions

```python
# Sort strings by length
words = ['python', 'is', 'awesome']
sorted_words = sorted(words, key=lambda x: len(x))  # ['is', 'python', 'awesome']

# Sort dictionaries by a specific field
users = [
    {'name': 'Alice', 'age': 25, 'grade': 'C'},
    {'name': 'Bob', 'age': 30, 'grade': 'B'},
    {'name': 'Charlie', 'age': 20, 'grade': 'A'}
]
sorted_users = sorted(users, key=lambda x: x['age'])  # Sorts by age

# Using lambda function to extract specific fields from a dictionary
user_tuples = list(map(lambda x: (x['name'], x['age'], x['grade']), users))

# Alternative using list comprehension (more idiomatic/Pythonic)
user_tuples = [(user['name'], user['age'], user['grade']) for user in users]


# Result: [('Alice', 25, 'C'), ('Bob', 30, 'B'), ('Charlie', 20, 'A')]
# Sort by age first, then by grade
sorted_users = sorted(users, key=lambda x: (x['age'], x['grade'])) # for dictionaries
sorted_user_tuples = sorted(user_tuples, key=lambda name, age, grade: (age, grade)) # for tuples

# You can do the same thing with an underscore as the first argument, because we don't actually care about the name
# The underscore is a convention for indicating that the value is not used
sorted_user_tuples = sorted(user_tuples, key=lambda _, age, grade: (age, grade)) # same as the previous example

# Sort complex objects
from dataclasses import dataclass

@dataclass
class Person:
    name: str
    age: int
    grade: str


people = [
    Person('Alice', 25, 'A'),
    Person('Bob', 30, 'B'),
    Person('Charlie', 20, 'C')
]

# Sort by age
sorted_people = sorted(people, key=lambda x: x.age)
# Sort by multiple criteria: grade first, then by age
sorted_people = sorted(people, key=lambda x: (x.grade, x.age))
```

### As simple transformations

Lambda functions are often used when we need to transform data from one format to another in very straightforward ways.

```python
# Quick data conversion
to_celsius = lambda f: (f - 32) * 5/9
to_fahrenheit = lambda c: (c * 9/5) + 32

# Simple mathematical operations
square = lambda x: x**2
add = lambda x, y: x + y

# Format strings
format_name = lambda first, last: f"{last.upper()}, {first.title()}"
```

### With default arguments

You can also use default arguments in lambda functions, just like you would with regular functions.

```python
# Lambda with default values
greeting = lambda name, greeting="Hello": f"{greeting}, {name}!"
print(greeting("Alice"))  # "Hello, Alice!"
print(greeting("Bob", "Hi"))  # "Hi, Bob!"

# Conditional logic
get_status = lambda x: "Pass" if x >= 60 else "Fail"
```

## Functional programming patterns

In addition to the Object-Oriented Programming paradigm (as via classes), Python supports several functional programming
patterns via built-in functions like `map()`, `filter()`, and `reduce()`. While list comprehensions are often preferred
in Python, these patterns are still useful to know.

### Transforming data with `map()`

The `map()` function is useful when you need to apply a function to each item in a collection. Think of it as a very concise
version of a for loop. It says, "For each item in the collection, apply the function to it and return the result".

```python
# Convert temperatures from Celsius to Fahrenheit
celsius = [0, 10, 20, 30]
# we cast the result to a list because map returns an iterator
fahrenheit = list(map(lambda c: (c * 9/5) + 32, celsius))

# Format strings in a list — make everything title case
names = ['alice', 'bob', 'charlie']
formatted = list(map(lambda x: x.title(), names)) # "Alice", "Bob", "Charlie"
```

### Filtering data with `filter()`

The `filter()` function is useful when you need to filter items in a collection based on a condition. It says, "For each item in the collection, get me the items that match the condition and return them in a new collection".

```python
# Filter out negative numbers
numbers = [-2, -1, 0, 1, 2]
positives = list(filter(lambda x: x > 0, numbers)) # [1, 2]

# Filter dictionaries by condition
items = [
    {'name': 'apple', 'price': 0.50},
    {'name': 'banana', 'price': 0.25},
    {'name': 'cherry', 'price': 1.00}
]
affordable_items = list(filter(lambda x: x['price'] < 0.75, items))
# gives us: [{'name': 'apple', 'price': 0.50}, {'name': 'banana', 'price': 0.25}]
```

### Combining with `reduce()`

The `reduce()` function from the `functools` module is used to process a sequence or collection and build a single
result by applying a function to pairs of elements. It works by:

1. Taking the first two items from the sequence
2. Applying the function to them to get an intermediate result
3. Taking that result and the next item from the sequence
4. Repeating until all items are processed

Here's an example of how reduce works with multiplication, multiplying all the numbers in a list together:

```python
from functools import reduce

numbers = [1, 2, 3, 4]
# Get the product of all numbers in the list using `reduce`
# reduce(lambda x, y: x * y, numbers) works like this:
# Step 1: 1 * 2 = 2
# Step 2: 2 * 3 = 6
# Step 3: 6 * 4 = 24
product = reduce(lambda x, y: x * y, numbers)  # Result: 24

# You can also provide an initial value as a third argument
product = reduce(lambda x, y: x * y, numbers, 10)  # Starts with 10, result: 240
```

While Python has several built-in functions that can be used to reduce collections in specific ways (e.g. `sum()`,
`join()`, etc.), `reduce()` is a more general purpose method that can be used to reduce any collection. You will see it
used from time to time.

```python
from functools import reduce

# Sum all numbers in a list (though the sum() built-in is preferred)
total = reduce(lambda x, y: x + y, [1, 2, 3, 4])  # 10

# Join strings with a separator (though the join() built-in is preferred)
words = ['hello', 'world', 'in', 'python']
sentence = reduce(lambda x, y: x + ' ' + y, words)  # "hello world in python"

# Find maximum value in a list of dictionaries (though max() built-in is preferred)
transactions = [
    {'amount': 100},
    {'amount': 200},
    {'amount': 150}
]
max_transaction = reduce(lambda x, y: x if x['amount'] > y['amount'] else y, transactions)
# Returns: {'amount': 200}
```

## Counting and aggregating

Often, you'll need to _count_ things: how many times does a particular item appear in a list, how many unique items are
in a list, how many times does an event occur, etc. There are many ways to do so:

### Counting items

```python
from collections import Counter

# Count occurrences in a list
words = ['apple', 'banana', 'apple', 'cherry']
word_counts = Counter(words)  # Counter({'apple': 2, 'banana': 1, 'cherry': 1})

# Count with a dictionary
counts = {}
for item in items:
    counts[item] = counts.get(item, 0) + 1

# Using defaultdict
from collections import defaultdict
counts = defaultdict(int)
for item in items:
    counts[item] += 1
```

### Finding the most (or least) common items

```python
word_counts = Counter(words)
# Get the 3 most common words and their counts
three_most_common_words = word_counts.most_common(3)

# Get the least common word and its count
# Notice how we still use the most_common method, but we choose the last item
# which is now the least common one
least_common_word = word_counts.most_common()[-1]
```

### Finding the biggest and smallest items

#### In dictionaries

```python
# Convert Counter to a dictionary
counts = dict(word_counts)

# Find the key associated with the maximum value in a dictionary
word_with_most_occurrences = max(counts, key=counts.get)

# Find the key associated with the minimum value in a dictionary
word_with_least_occurrences = min(counts, key=counts.get)
```

#### In lists

```python
# Find the smallest value in a list
numbers = [1, 2, 3, 4, 5]
smallest_number = min(numbers)

# Find the largest value in a list
largest_number = max(numbers)

# Find the index of the smallest value in a list
smallest_number_index = numbers.index(smallest_number)

# Find the index of the largest value in a list
largest_number_index = numbers.index(largest_number)
```

#### In tuples

Suppose that you have a list of tuples, where each tuple contains something and a number. You can use the `min` and `max` functions to find the smallest and largest items, respectively.

```python
items = [("apple", 1), ("banana", 2), ("cherry", 3)]
smallest_item = min(items, key=lambda item: item[1])
largest_item = max(items, key=lambda item: item[1])

# You can also use tuple unpacking if you prefer, since this is a little more readable
smallest_item = min(items, key=lambda name, count: count)
largest_item = max(items, key=lambda name, count: count)
```

#### In objects

```python
class Car:
    def __init__(self, brand, model, year, mileage=None):
        self.brand = brand
        self.model = model
        self.year = year
        self.mileage = mileage or 0 # initialize odometer to 0 if no mileage is provided

    def drive(self, miles):
        self.mileage += miles

    def __str__(self):
        return f"{self.brand} {self.model} ({self.year}): Driven {self.mileage} miles"

cars = [
    Car("Toyota", "Corolla", 2020, 10000),
    Car("Ford", "Mustang", 2021, 5000),
    Car("Chevrolet", "Camaro", 2022, 2000),
]

# Find the car with the most miles
car_with_most_miles = max(cars, key=lambda x: x.mileage)

# Find the car with the least miles
car_with_least_miles = min(cars, key=lambda x: x.mileage)
```

## Working with collections

Collections are fundamental to Python programming, and there are several common operations you might
need to perform on them. I regularly use the following patterns.

### Zipping and unzipping

```python
# Basic zipping of two lists
names = ['Alice', 'Bob', 'Charlie']
ages = [20, 25, 30]
people = list(zip(names, ages))  # [('Alice', 20), ('Bob', 25), ('Charlie', 30)]

# Unzipping (destructuring)
# there is no unzip function, but you can reverse the process with the * operator
names_back, ages_back = zip(*people)  # Converts back to separate lists!

# Zipping with different length lists (stops at shortest)
a = [1, 2, 3]
b = ['a', 'b']  # shorter list
zipped = list(zip(a, b))  # [(1, 'a'), (2, 'b')]

# Enumerate when you need both index and value
# Enumerate can be thought of as zipping a range object of the same length as the
# collection you pass to it.
for i, name in enumerate(names):
    print(f"{i}: {name}")  # "0: Alice", "1: Bob", etc.

# this is the same as:
for i, name in zip(range(len(names)), names):
    print(f"{i}: {name}")  # "0: Alice", "1: Bob", etc.

# Enumerate with start index (the default is 0)
for i, name in enumerate(names, start=1):
    print(f"{i}: {name}")  # "1: Alice", "2: Bob", etc.
```

### Reversing lists

```python
# Reverse a list in place
numbers = [1, 2, 3, 4, 5]
numbers.reverse()  # Original list is modified -- no need to assign to a new variable

# Create a reversed copy
original = [1, 2, 3, 4, 5]
reversed_copy = original[::-1]  # New reversed list -- note the use of the slice operator

# Using reversed() function (returns an iterator, not a list itself)
for num in reversed(numbers):
    print(num)

# Reverse a string
text = "Hello"
reversed_text = text[::-1]  # "olleH" -- note the use of the slice operator
```

### Combining and splitting collections

```python
# Concatenating lists
list1 = [1, 2, 3]
list2 = [4, 5, 6]
combined = list1 + list2  # [1, 2, 3, 4, 5, 6]

# alternatively, you can achieve the same result by
# unpacking the lists with the * operator
combined = [*list1, *list2]  # [1, 2, 3, 4, 5, 6]

# Extending a list
list1.extend(list2)  # Modifies list1 in place to also have the elements of list2
# no need to assign to a new variable!
# list1 is now [1, 2, 3, 4, 5, 6]

# Splitting lists
items = [1, 2, 3, 4, 5, 6]
middle = len(items) // 2 # note the use of integer division -- two slashes!
first_half = items[:middle]
second_half = items[middle:]

# Chunking a list into fixed-size pieces with a custom function
# We can use itertools to help us do this -- don't worry if this is cryptic!
from itertools import islice

def chunk_list(lst, chunk_size):
    iterator = iter(lst) # create an iterator from the list
    return list(iter(lambda: list(islice(iterator, chunk_size)), []))

numbers = [1, 2, 3, 4, 5, 6, 7]
chunk_size = 3
chunks = chunk_list(numbers, chunk_size)  # [[1, 2, 3], [4, 5, 6], [7]]

# Alternative one-liner using itertools only -- even more cryptic!
from itertools import islice, chain
chunk_size = 3
chunks = list(zip(*[iter(numbers)] * chunk_size))  # Only works when len(numbers) is divisible by chunk_size

```

### Finding common elements

```python
# Intersection of two lists (no duplicates)
list1 = [1, 2, 2, 3, 4]
list2 = [2, 4, 5, 6]
common = list(set(list1) & set(list2))  # [2, 4]

# Union of two lists (no duplicates)
all_unique = list(set(list1) | set(list2))  # [1, 2, 3, 4, 5, 6]

# Difference between lists (elements in first but not in second; no duplicates)
difference = list(set(list1) - set(list2))  # [1, 3]

# Symmetric difference (elements in either but not both; no duplicates)
symmetric_difference = list(set(list1) ^ set(list2))  # [1, 3, 5, 6]
```

### Grouping elements

```python
from itertools import groupby
from operator import itemgetter

# Group consecutive elements
numbers = [1, 1, 1, 2, 2, 3, 4, 4, 4]
for key, group in groupby(numbers):
    print(f"{key}: {list(group)}")  # "1: [1, 1, 1]", "2: [2, 2]", etc.

# Group items by a key
items = [
    ('A', 1), ('A', 2), ('B', 1), ('B', 2)
]
# Sort first - groupby() only groups consecutive elements
items.sort(key=itemgetter(0))
for key, group in groupby(items, key=itemgetter(0)):
    print(f"{key}: {list(group)}")  # "A: [('A', 1), ('A', 2)]", etc.
```

### Chain and combine iterables

```python
from itertools import chain, combinations, permutations

# Chain multiple iterables together
list1 = [1, 2]
list2 = [3, 4]
list3 = [5, 6]
chained = list(chain(list1, list2, list3))  # [1, 2, 3, 4, 5, 6]

# Generate all possible combinations
items = ['A', 'B', 'C']
# Get all 2-item combinations
pairs = list(combinations(items, 2))  # [('A', 'B'), ('A', 'C'), ('B', 'C')]

# Generate all possible permutations
items = ['A', 'B', 'C']
permutations = list(permutations(items))
# [('A', 'B', 'C'), ('A', 'C', 'B'), ('B', 'A', 'C'), ('B', 'C', 'A'), ('C', 'A', 'B'), ('C', 'B', 'A')]
```

## Working with classes

Classes are at the heart of object-oriented programming, so it's important to get comfortable with
them. Here are some helpful ways to work with classes.

### Essential dunder methods

By dunder methods, we mean methods that start and end with double underscores. They are also
sometimes called "magic methods".

Let's look at an example of a class that represents a book. We will use some of the dunder methods
to make the class behave in a few different ways.

```python
class Book:
    def __init__(self, title: str, author: str, pages: int):
        """Initialize the book"""
        self.title = title
        self.author = author
        self.pages = pages
        self._current_page = 0  # "private" attributes are prefaced with an underscore
        # they aren't really private, but we use this convention to indicate to other developers
        # that these attributes are internal to the class and should not be accessed directly

    # String representation for debugging -- used by repr()
    def __repr__(self):
        return f"Book(title='{self.title}', author='{self.author}', pages={self.pages})"

    # String representation for users -- used by print() and str()
    def __str__(self):
        return f"{self.title} by {self.author}"

    # Make it possible to compare two books
    def __eq__(self, other: 'Book'):
        if not isinstance(other, Book):
            return NotImplemented
        return (
            self.title == other.title and
            self.author == other.author
        )

    # there are also __lt__ (<), __le__ (<=), __gt__ (>), and __ge__ (>=) methods,
    # which make it possible to compare methods of a class, but they wouldn't make
    # much sense for a book class.

    # Make the object hashable (for use in sets/dicts)
    def __hash__(self):
        return hash((self.title, self.author))

    # Get the length of the book (used by len())
    def __len__(self):
        return self.pages

    # Make the object iterable (used by for loops and other functions that iterate over collections)
    def __iter__(self):
        self._current_page = 0
        return self

    # Get the next item in the iterable (used by for loops and other functions that iterate over collections)
    def __next__(self):
        if self._current_page >= self.pages:
            raise StopIteration
        self._current_page += 1
        return f"Page {self._current_page}"

# Usage example:
book = Book("Python Patterns", "John Doe", 200)
print(repr(book))  # Book(title='Python Patterns', author='John Doe', pages=200)
print(str(book))   # Python Patterns by John Doe
print(len(book))   # 200

# Iteration example
for page in book:
    print(page)    # Prints "Page 1", "Page 2", etc.
```

### Property decorators and validation

Sometimes, in your classes, you want to give the user a simplified interface for getting and setting
properties, while keeping them (nominally) private and allowing the user to avoid common errors. For
example, in a Temperature class, you might want to ensure that a temperature value is always a
number, and that the number is above absolute zero. Property decorators come to the rescue in these
cases.

```python
class Temperature:
    def __init__(self, celsius=0):
        self._celsius = celsius
        # note the use of a private attribute, prefaced with an underscore

    # Getter -- gets the value of the attribute
    @property
    def celsius(self):
        return self._celsius

    # Setter with validation -- sets the value of the attribute safely
    @celsius.setter
    def celsius(self, value):
        # check if the value is either an int or a float
        if not isinstance(value, (int, float)):
            raise TypeError("Temperature must be a number")

        # check if the value is above absolute zero
        if value < -273.15:  # Absolute zero
            raise ValueError("Temperature below absolute zero!")

        # set the attribute
        self._celsius = value

    # Computed property -- derived from the attribute on the fly
    @property
    def fahrenheit(self):
        # convert the celsius value to fahrenheit
        return (self.celsius * 9/5) + 32

    # Setter for the computed property -- sets the value of the attribute safely
    @fahrenheit.setter
    def fahrenheit(self, value):
        # convert the fahrenheit value to celsius
        self.celsius = (value - 32) * 5/9

# Usage:
temp = Temperature(25)
print(temp.celsius)     # 25
print(temp.fahrenheit)  # 77.0

temp.celsius = 30
print(temp.fahrenheit)  # 86.0

temp.fahrenheit = 68
print(temp.celsius)     # 20.0

# These will raise errors:
# temp.celsius = "hot"  # TypeError
# temp.celsius = -300   # ValueError
```

### Context managers

Context managers are used to manage resources, such as opening and closing a file or a database
connection. Often you will see them used with the `with` statement, which ensures that the resource
is properly closed after its block finishes, even if an exception is raised at some point. If we
open a resource without eventually closing it, our computer will eventually run out of memory and
crash. Rather than having to rely on our faulty human memory to remember to close the resource, we
can use a context manager to ensure that the resource is properly closed.

```python
class DatabaseConnection:
    def __init__(self, host, port):
        self.host = host
        self.port = port
        self.connected = False

    def __enter__(self):
        # Set up the connection
        print(f"Connecting to {self.host}:{self.port}")
        self.connected = True
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        # Clean up the connection
        print("Closing connection")
        self.connected = False
        # Return True to suppress any exceptions, False to propagate them
        return False

    def query(self, sql):
        if not self.connected:
            raise RuntimeError("Not connected!")
        print(f"Executing: {sql}")

# Usage with context manager:
with DatabaseConnection("localhost", 5432) as db: # 5432 is the default port for PostgreSQL, a common open-source database
    db.query("SELECT * FROM users")

# Connection is automatically closed after the with block!
```

## Working with files

We often need to read and write files in our programs. For example, we might need to read a configuration file, or load
in data via a CSV file or a text file. Here are some common ways to work with files.

### Reading files

```python
# Read entire file — note the use of a context manager (the `with` statement)
# This ensures that the file is properly closed after its block finishes, even if an exception is raised at some point
with open('file.txt', 'r') as f:
    content = f.read()

# Read line by line
with open('file.txt', 'r') as f:
    for line in f:
        line = line.strip()  # Remove trailing newlines and whitespace characters
        # Logic for processing line goes here

# Read CSV files
import csv
with open('data.csv', 'r') as f:
    reader = csv.reader(f)
    for row in reader:
        # Logic for processing row goes here
```

### Writing files

```python
# Write lines to a file
lines = ['line 1', 'line 2', 'line 3']
with open('output.txt', 'w') as f:
    for line in lines:
        f.write(f"{line}\n")

# Write CSV files
with open('output.csv', 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerows(data)
```

### Finding files

The `glob` module provides a way to find files using pattern matching. This is particularly useful when you need to process multiple files that follow a certain naming pattern.

```python
from glob import glob
import os

# Find all Python files in current directory
python_files = glob('*.py')

# Find all files in a specific directory
files_in_data = glob('data/*')

# Find files recursively (including subdirectories)
all_csv_files = glob('**/*.csv', recursive=True)

# Find files with multiple extensions
data_files = glob('data/*.{csv,txt,xlsx}', recursive=True)

# Combine with os.path for more control
for file_path in glob('data/*.csv'):
    filename = os.path.basename(file_path)  # Get just the filename
    directory = os.path.dirname(file_path)  # Get just the directory path

    # Process each file
    with open(file_path, 'r') as f:
        content = f.read()
        # ... process content ...

# We will learn more about pandas in Chapter 14; come back here when you have read that chapter
# Common pattern: process all matching files
import pandas as pd

# Read and combine all CSV files in a directory
all_dataframes = []
for file_path in glob('data/*.csv'):
    df = pd.read_csv(file_path)
    all_dataframes.append(df)

# Combine all dataframes into a single dataframe
combined_data = pd.concat(all_dataframes)
```

`glob` uses Unix shell-style wildcards:

- `*` matches any number of characters (except leading dots)
- `?` matches any single character
- `[seq]` matches any character in the sequence. For example:
  - `[abc]` matches 'a', 'b', or 'c'
  - `[0-9]` matches any digit
  - `data[123].txt` matches 'data1.txt', 'data2.txt', or 'data3.txt'
- `[!seq]` matches any character NOT in the sequence. For example:
  - `[!abc]` matches any character except 'a', 'b', or 'c'
  - `[!0-9]` matches any non-digit
  - `data[!123].txt` matches 'data4.txt' or 'data5.txt', but not 'data1.txt'

## Working with file paths

The `pathlib` module provides an object-oriented interface to filesystem paths. It's more powerful
and easier to use than the older `os.path` module.

```python
from pathlib import Path

# Create path objects
current_dir = Path.cwd()  # Get current working directory
home_dir = Path.home()    # Get your home directory
data_dir = Path('data')   # An example relative path -- this points to the data directory in the current working directory
abs_path = Path('/absolute/path/to/file.txt')  # An example absolute path -- this points to a file at a specific location on your computer

# Joining paths (notice no need for os.path.join or dealing with backslashes vs. forward slashes)
config_file = home_dir / '.config' / 'app' / 'config.yml'
data_file = data_dir / 'experiment_1' / 'results.csv'

# Path components
filename = data_file.name          # 'results.csv'
stem = data_file.stem             # 'results'
extension = data_file.suffix      # '.csv'
parent_dir = data_file.parent     # Path('data/experiment_1')

# Check path properties
exists = data_file.exists()       # Does the file exist?
is_file = data_file.is_file()    # Is it a regular file?
is_dir = data_dir.is_dir()       # Is it a directory?

# Create directories
data_dir.mkdir(exist_ok=True)             # Create single directory -- if it already exists, do nothing
data_dir.mkdir(parents=True, exist_ok=True)  # Create parent directories too -- if they already exist, do nothing

# List directory contents
python_files = list(current_dir.glob('*.py'))     # List Python files in the current directory
all_text_files = list(current_dir.rglob('*.txt'))      # Recursively list all .txt files in the current directory and all subdirectories

# Common operations
for path in data_dir.iterdir():  # Iterate over directory contents
    if path.suffix == '.txt':    # Check file extension
        # Read text file
        content = path.read_text()
        # Write text file
        path.write_text('new content')
        # Get file size
        size = path.stat().st_size

# Real-world example: organize files by extension
def organize_files(directory):
    directory = Path(directory)
    # Create directories for each extension
    for file_path in directory.iterdir():
        if file_path.is_file():
            # Get the extension (convert to lowercase for consistency)
            ext = file_path.suffix.lower()
            if ext:  # Only process files with extensions
                # Create directory for this extension
                ext_dir = directory / ext[1:]  # Remove the dot from extension to name the directory
                ext_dir.mkdir(exist_ok=True)
                # Move file to appropriate directory
                file_path.rename(ext_dir / file_path.name)

# Example usage:
# organize_files('downloads')  # Organizes files in downloads directory by extension!
```

The `pathlib` module makes it much easier to work with file paths compared to the older `os.path` approach, so I recommend using it instead. It makes it especially easy to combine paths, to work with parts of paths, and has cross-platform consistency (so you don't have to worry about backslashes vs forward slashes in Windows vs. Mac/Linux).

## Data transformation

Much of the job of a researcher is to transform some messy data into a more usable format. Rarely are the data you need
already pre-processed for you. As such, getting comfortable with data transformation is a crucial skill. You may find
yourself relying on these operations frequently.

### Filtering lists

```python
# Filter with list comprehension
numbers = [1, 2, 3, 4, 5, 6]
evens = [x for x in numbers if x % 2 == 0]

# Filter with built-in filter function
evens = list(filter(lambda x: x % 2 == 0, numbers))
```

### Transforming data

```python
# Transform and filter in one step
numbers = [1, 2, 3, 4, 5]
squared_evens = [x**2 for x in numbers if x % 2 == 0]

# Transform dictionary values
prices = {'apple': 0.5, 'banana': 0.25}
doubled_prices = {k: v * 2 for k, v in prices.items()}
```

## Working with nested data

Data is often nested (meaning that you have a dictionary or list that contains another dictionary or list, and so on,
potentially to a great depth), and you may need to access or transform nested data — I do this all the time, and these
are some of the ways I do it.

### Safely accessing nested dictionaries

```python
# Using get() with default values
data = {'user': {'name': 'John', 'age': 30}}
name = data.get('user', {}).get('name', 'Unknown')
# we do this to avoid a KeyError, which would occur
# if we tried to access data['user']['name'] directly if the key is not present

# Or we could use a try-except block (but this is less readable)
try:
    name = data['user']['name']
except KeyError:
    name = 'Unknown'
```

### Flattening nested lists

Sometimes you may need to flatten a list of lists into a single list. You can do this with a list comprehension or with
the `itertools` module.

```python
# Flatten a list of lists
nested = [[1, 2], [3, 4], [5, 6]]
flattened = [item for sublist in nested for item in sublist] # [1, 2, 3, 4, 5, 6]

# Flatten with itertools
import itertools
flattened = list(itertools.chain.from_iterable(nested)) # [1, 2, 3, 4, 5, 6]
```

## Error handling

Errors are a fact of life in programming. You can't always predict when they'll occur, but you can prepare for them, and
handle them gracefully with try-except blocks. Review [Chapter 2.10. Try and Except](../CH02/2.10.%20Try%20and%20Except.md) if any
of this is unfamiliar.

### Graceful error handling

It's not a good idea to catch all exceptions with a bare `except` clause. Instead, specify the exceptions you expect to
handle, and catch the rest with a more general `except` clause that also logs the error.

```python
# Handle multiple exceptions
try:
    value = int(user_input)
    result = 100 / value
except ValueError:
    print("Please enter a valid number")
except ZeroDivisionError:
    print("Cannot divide by zero")
except Exception as e:
    print(f"An unexpected error occurred: {e}")
```

## Working with dates and times

Dates and times are a fact of life in many scientific and engineering applications. Within my own work in psychology, I
have to deal with when participants completed my tasks, their reaction times when making responses, and so on. May you
find these examples helpful.

### Date manipulation

```python
from datetime import datetime, timedelta

# Get current date/time
now = datetime.now()

# Add/subtract time
tomorrow = now + timedelta(days=1)
last_week = now - timedelta(weeks=1)

# Format dates
formatted = now.strftime("%Y-%m-%d %H:%M:%S")
```

These patterns represent common solutions to several frequently encountered programming tasks. While there are often
multiple ways to solve a problem, these are well-worn patterns, providing tested, readable approaches that you can build
upon.

## Dealing with randomness

Whether you're creating random data, choosing random samples, or shuffling data, scientists find themselves needing to harness the power of randomness regularly.

### Basic random operations

```python
import random

# Generate a random float between 0 and 1
random_float = random.random()

# Generate random integer in range (inclusive)
dice_roll = random.randint(1, 6)

# Choose from a range with step size
even_number = random.randrange(0, 101, 2)  # Random even number 0-100

# Random choice from sequence
colors = ['red', 'green', 'blue']
chosen_color = random.choice(colors) # pick one of the colors at random

# Multiple random choices (with replacement)
samples = random.choices(colors, k=5)  # Can pick the same color multiple times

# Multiple random choices (without replacement)
unique_samples = random.sample(colors, k=2)  # Each color can only be picked once
```

### Shuffling data

```python
# Shuffle a list in place
cards = ['A', '2', '3', '4', '5']
random.shuffle(cards)  # Original list is modified in-place -- no need to assign to a new variable

# Create a shuffled copy without modifying original
original = [1, 2, 3, 4, 5]
shuffled = random.sample(original, k=len(original))
```

### Setting random seeds

When you need reproducible random results (e.g., for scientific experiments or testing):

```python
# Set seed for reproducibility
random.seed(42)  # Any integer works as seed
result1 = random.random()
result2 = random.random()

# Using the same seed later will produce the same sequence
random.seed(42)
assert result1 == random.random()  # True
assert result2 == random.random()  # True
```

### Working with probability distributions

For more sophisticated random number generation, use NumPy's random module.

```python
import numpy as np

# Normal (Gaussian) distribution
gaussian_values = np.random.normal(loc=0, scale=1, size=1000)  # mean=0, std=1

# Uniform distribution
uniform_values = np.random.uniform(low=0, high=10, size=100)

# Random integers with custom probabilities
outcomes = [1, 2, 3]
probabilities = [0.2, 0.5, 0.3]  # Must sum to 1
weighted_choice = np.random.choice(outcomes, p=probabilities)
```

### Random sampling in pandas

We'll encounter pandas in [Chapter 14. Data Analysis and DataFrames](../CH14/14.0.%20Data%20Analysis%20and%20DataFrames.md)
but for now, here are some examples of how its convenient sampling methods can be used.

```python
import pandas as pd

df = pd.DataFrame({'A': range(1, 101)})

# Random sample of n rows
sample_n = df.sample(n=10)  # Get 10 random rows

# Random sample by percentage
sample_frac = df.sample(frac=0.1)  # Get 10% of rows

# Stratified sampling
stratified = df.groupby('category').sample(n=5)  # 5 samples from each category
```

Next: [8.8. Common Pitfalls](8.8.%20Common%20Pitfalls.md)<br>
[Previous: 8.6. Decorators](8.6.%20Decorators.md)
